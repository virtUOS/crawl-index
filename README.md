# Crawl & Index
**(Under construction)**

This project aims to create an index  by crawling web pages, extracting their text content, and summarizing it using a local AI model. The summarized data, along with metadata, is then stored in ChromaDB.

## Table of Contents

- [Setup and Installation](#setup-and-installation)
- [Running the Project](#running-the-project)
- [Configuration](#configuration)
- [Contributing](#contributing)
- [License](#license)


## Setup and Installation

### Prerequisites
- [Docker](https://www.docker.com/products/docker-desktop)
- [Docker Compose](https://docs.docker.com/compose/install/)





